{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data types\n",
      "0      object\n",
      "1      object\n",
      "2      object\n",
      "3      object\n",
      "4      object\n",
      "5      object\n",
      "6      object\n",
      "7      object\n",
      "8      object\n",
      "9      object\n",
      "10     object\n",
      "11     object\n",
      "12     object\n",
      "13     object\n",
      "14     object\n",
      "15     object\n",
      "16     object\n",
      "17     object\n",
      "18     object\n",
      "19     object\n",
      "20     object\n",
      "21     object\n",
      "22    float64\n",
      "23     object\n",
      "24     object\n",
      "25     object\n",
      "26     object\n",
      "27    float64\n",
      "28     object\n",
      "29     object\n",
      "30     object\n",
      "31    float64\n",
      "32     object\n",
      "33    float64\n",
      "34    float64\n",
      "35     object\n",
      "36    float64\n",
      "37     object\n",
      "38     object\n",
      "39     object\n",
      "40     object\n",
      "41     object\n",
      "42     object\n",
      "43     object\n",
      "44     object\n",
      "45     object\n",
      "46     object\n",
      "47     object\n",
      "48     object\n",
      "49     object\n",
      "50     object\n",
      "51     object\n",
      "52     object\n",
      "53     object\n",
      "54     object\n",
      "55     object\n",
      "56     object\n",
      "57     object\n",
      "dtype: object\n",
      "Missing Values:\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    0\n",
      "30    0\n",
      "31    0\n",
      "32    0\n",
      "33    0\n",
      "34    0\n",
      "35    0\n",
      "36    0\n",
      "37    0\n",
      "38    0\n",
      "39    0\n",
      "40    0\n",
      "41    0\n",
      "42    0\n",
      "43    0\n",
      "44    0\n",
      "45    0\n",
      "46    0\n",
      "47    0\n",
      "48    0\n",
      "49    0\n",
      "50    0\n",
      "51    0\n",
      "52    0\n",
      "53    0\n",
      "54    0\n",
      "55    0\n",
      "56    0\n",
      "57    0\n",
      "dtype: int64\n",
      "\n",
      "NaN Values:\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    0\n",
      "30    0\n",
      "31    0\n",
      "32    0\n",
      "33    0\n",
      "34    0\n",
      "35    0\n",
      "36    0\n",
      "37    0\n",
      "38    0\n",
      "39    0\n",
      "40    0\n",
      "41    0\n",
      "42    0\n",
      "43    0\n",
      "44    0\n",
      "45    0\n",
      "46    0\n",
      "47    0\n",
      "48    0\n",
      "49    0\n",
      "50    0\n",
      "51    0\n",
      "52    0\n",
      "53    0\n",
      "54    0\n",
      "55    0\n",
      "56    0\n",
      "57    0\n",
      "dtype: int64\n",
      "Class Distribution:\n",
      "ham      2788\n",
      "spam     1813\n",
      "Class       1\n",
      "Name: 57, dtype: int64\n",
      "Balance Ratio: 0.650286944045911\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('spam.csv', header=None)\n",
    "\n",
    "# Assuming the last column is the target variable and the rest are features\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Checking data types of all features\n",
    "print(\"The data types\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Check for NaN values\n",
    "nan_values = data.isna().sum()\n",
    "\n",
    "# Print the results\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "print(\"\\nNaN Values:\")\n",
    "print(nan_values)\n",
    "\n",
    "# Exclude the target variable\n",
    "target_variable = data.iloc[:, -1]\n",
    "\n",
    "# Check the distribution of the target variable\n",
    "class_distribution = target_variable.value_counts()\n",
    "\n",
    "# Print the distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(class_distribution)\n",
    "\n",
    "# Calculate the balance ratio\n",
    "balance_ratio = class_distribution[1] / class_distribution[0]\n",
    "print(\"Balance Ratio:\", balance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for categorical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "if not categorical_features.empty:\n",
    "    # If categorical features are found, one-hot encode them\n",
    "    X = pd.get_dummies(X, columns=categorical_features)\n",
    "\n",
    "# Convert feature names to strings\n",
    "X.columns = X.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=3601, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused Model Results:\n",
      "Accuracy: 0.9133574007220217\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Class       1.00      0.00      0.00         1\n",
      "         ham       0.93      0.93      0.93      2190\n",
      "        spam       0.89      0.89      0.89      1410\n",
      "\n",
      "    accuracy                           0.91      3601\n",
      "   macro avg       0.94      0.61      0.61      3601\n",
      "weighted avg       0.91      0.91      0.91      3601\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   0    1    0]\n",
      " [   0 2028  162]\n",
      " [   0  149 1261]]\n"
     ]
    }
   ],
   "source": [
    "# Fused model with Decision Tree, Gaussian Na√Øve Bayes, and Logistic Regression\n",
    "\n",
    "# Create individual classifiers\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "nb_classifier = GaussianNB()\n",
    "lr_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Create the fused model using the majority voting rule\n",
    "fused_model = VotingClassifier(estimators=[\n",
    "    ('decision_tree', dt_classifier),\n",
    "    ('naive_bayes', nb_classifier),\n",
    "    ('logistic_regression', lr_classifier)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate the fused model\n",
    "fused_model.fit(X_train[:1000], y_train[:1000])\n",
    "y_pred_fused = fused_model.predict(X_test)\n",
    "\n",
    "# Print accuracy, per class accuracy, and confusion matrix for the fused model\n",
    "print(\"Fused Model Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_fused))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_fused,zero_division=1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_fused))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost Results:\n",
      "Accuracy: 0.8858650374895862\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Class       1.00      0.00      0.00         1\n",
      "         ham       0.90      0.91      0.91      2190\n",
      "        spam       0.86      0.84      0.85      1410\n",
      "\n",
      "    accuracy                           0.89      3601\n",
      "   macro avg       0.92      0.59      0.59      3601\n",
      "weighted avg       0.89      0.89      0.89      3601\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   0    0    1]\n",
      " [   0 2000  190]\n",
      " [   0  220 1190]]\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Ensemble with Decision Trees as base learner\n",
    "# Create AdaBoost model with Decision Tree as the base learner\n",
    "adaboost_model = AdaBoostClassifier(estimator=DecisionTreeClassifier(random_state=42), n_estimators=50)\n",
    "\n",
    "# Train and evaluate the AdaBoost model\n",
    "adaboost_model.fit(X_train[:1000], y_train[:1000])\n",
    "y_pred_adaboost = adaboost_model.predict(X_test)\n",
    "\n",
    "# Print accuracy, per class accuracy, and confusion matrix for AdaBoost\n",
    "print(\"\\nAdaBoost Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_adaboost))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_adaboost,zero_division=1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_adaboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9169675090252708\n",
      "Confusion Matrix:\n",
      "[[   0    1    0]\n",
      " [   0 2104   86]\n",
      " [   0  212 1198]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Class       0.00      0.00      0.00         1\n",
      "         ham       0.91      0.96      0.93      2190\n",
      "        spam       0.93      0.85      0.89      1410\n",
      "\n",
      "    accuracy                           0.92      3601\n",
      "   macro avg       0.61      0.60      0.61      3601\n",
      "weighted avg       0.92      0.92      0.92      3601\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Jupyter Notebook\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Jupyter Notebook\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Jupyter Notebook\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Compare with Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train[:1000], y_train[:1000])\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "confusion_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "classification_report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Report the results for Random Forest\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_rf)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for 50%-50% split:\n",
      "Fused Model Accuracy: 0.9356801390699696\n",
      "AdaBoost Accuracy: 0.9161234245980009\n",
      "Random Forest Accuracy: 0.9274228596262495\n",
      "\n",
      "Results for 60%-40% split:\n",
      "Fused Model Accuracy: 0.9337436640115858\n",
      "AdaBoost Accuracy: 0.8964518464880521\n",
      "Random Forest Accuracy: 0.9272266473569877\n",
      "\n",
      "Results for 70%-30% split:\n",
      "Fused Model Accuracy: 0.9286157666045934\n",
      "AdaBoost Accuracy: 0.9003724394785847\n",
      "Random Forest Accuracy: 0.9252017380509001\n",
      "\n",
      "Results for 80%-19% split:\n",
      "Fused Model Accuracy: 0.915263443780554\n",
      "AdaBoost Accuracy: 0.8843020097772949\n",
      "Random Forest Accuracy: 0.9185225420966866\n"
     ]
    }
   ],
   "source": [
    "# The impact of training sample size\n",
    "# Repeat the above steps for different training-test splits (50%-50%, 60%-40%, 70%-30%, and 80%-20%)\n",
    "\n",
    "for split in [0.5, 0.6, 0.7, 0.8]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=42)\n",
    "\n",
    "    # Train and evaluate the fused model\n",
    "    fused_model.fit(X_train, y_train)\n",
    "    y_pred_fused = fused_model.predict(X_test)\n",
    "\n",
    "    # Train and evaluate the AdaBoost model\n",
    "    adaboost_model.fit(X_train, y_train)\n",
    "    y_pred_adaboost = adaboost_model.predict(X_test)\n",
    "    \n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    y_pred_random_forest = rf_classifier.predict(X_test)\n",
    "\n",
    "    print(f\"\\nResults for {int(split*100)}%-{int((1-split)*100)}% split:\")\n",
    "    print(\"Fused Model Accuracy:\", accuracy_score(y_test, y_pred_fused))\n",
    "    print(\"AdaBoost Accuracy:\", accuracy_score(y_test, y_pred_adaboost))\n",
    "    print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_random_forest))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
